{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial Data in Python with GeoPandas \n",
    "\n",
    "## Introduction\n",
    "\n",
    "The goal of this notebook is to give you an **introduction** to working with geospatial data in Python using the `geopandas` package.  We will start with a **very** [Brief Introduction to Geospatial Data](https://docs.google.com/presentation/d/1d9GNcLDsnLxfLmrNRNZE976sHN5qNfkU9Rl2gabUsWc/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoPandas\n",
    "\n",
    "[GeoPandas](http://geopandas.org/) is a relatively new Python for working with geospatial data. In the last few years it has grown more powerful and stable. This really is great because previously it was quite complex to work with geospatial data in Python.  GeoPandas is now the go to package for working with geospatial data. \n",
    "\n",
    "`GeoPandas` provides convenient, unified access to the functionality of the [pandas](https://pandas.pydata.org/) package and the functionality provided by a number of lower level spatial data packages including [shapely](https://pypi.python.org/pypi/Shapely) for geometry processing, [fiona](https://pypi.python.org/pypi/Fiona) for spatial data file IO and `pyproj` for map projections and coordinate systems.\n",
    "\n",
    "So... let's get started with geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have geopandas installed, you can install it by uncommenting and running the following line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge geopandas\n",
    "## OR\n",
    "#!pip install geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also import some helper libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "!pip install pysal\n",
    "from pysal import *\n",
    "\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n",
    "\n",
    "In this notebook we will be working with historical census data for the USA and the Orleans Territory, most of which is now called Louisiana.  These data were obtained from the `NHGIS`, or *National Historical Geographic Information System* website ([IPUMS NHGIS, University of Minnesota, www.nhgis.org](https://www.nhgis.org))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Data files\n",
    "Take a look at the data files we will use with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l data   # take alook at the files in the data folder (directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in a Spatial Data\n",
    "\n",
    "Geopandas makes it easy to read in almost any kind of vector data file including the [ESRI Shapefile](https://en.wikipedia.org/wiki/Shapefile) with the [read_file](http://geopandas.org/io.html) command.  You simply put the name of the file in quotes and assign the resulting object to a simple yet informative variable name, here `usa1810`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usa1810 = gpd.read_file(\"data/uscounties_1810.shp\")  #US counties in 1810"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `read_file` command returns a geopandas `GeoDataFrame` object, or `gdf` for short. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(usa1810)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the `usa1810` gdf with the `head` command, just like you would look at a `pandas` dataframe.  Can you identify the name of the column that contains the  coordinate data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa1810.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the  coordinate data directy via the `geometry` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa1810.geometry.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What happens if you access just one geometry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa1810.geometry[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "In the cell below, rename the column NHGISNAM to 'county'.\n",
    "\n",
    "Hint from your `Intro to Pandas` notebook: \n",
    "\n",
    ">`unemployment.rename(columns={'month' : 'year_month'}, inplace=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping with GeoPandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the `usa1810` data with the geopandas `plot` method, which uses `matplotlib` and the matplotlib `pyplot` module under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa1810.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty cool to be able to make a map with a single command.  However, there is always room for improvement. \n",
    "You can find out more about the plotting options for basic maps in the [geopandas documentation](http://geopandas.org/mapping.html) and in the [matplotlib documentation](http://matplotlib.org/api/pyplot_api.html). \n",
    "\n",
    "We can use some options to make a prettier map. Take a minute to consider what each option does.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make blue counties red\n",
    "usa1810.plot(linewidth=0.25, edgecolor='black', facecolor='red',  figsize=(14,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Let's compare the extent of the USA in 1810 to the USA in 2017.\n",
    "\n",
    "- Read the file `usa_outline.shp` into a geopandas dataframe named `usa`.\n",
    "- Then, make a map of the `usa`, setting the `figsize` to (14,10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your code here\n",
    "\n",
    "# first read in the file\n",
    "\n",
    "# then plot the gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Any idea why the map of the plot looks so wide?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read in and plot the usa shapefile\n",
    "\n",
    "usa = gpd.read_file('data/usa_outline.shp')\n",
    "usa.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlays\n",
    "\n",
    "A key strength of geospatial data analysis is the ability to overlay data that are located in the same coordinate space. Let's overlay the USA in 1810 on top of the USA in 2017 to visualize the change.  We will explore two methods for doing this, as shown in the [GeoPandas documentation](http://geopandas.org/mapping.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1. Simple geopandas plot overlay\n",
    "\n",
    "base = usa.plot(color='white', edgecolor='black',  figsize=(14,10))\n",
    "usa1810.plot(ax=base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2. Setting Matplot lib options\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(14,10))  # Initialize the plot figure (drawing area) and axes (data area)\n",
    "ax.set_xlim([-180, -60]) # Set the x axis limit on the axes\n",
    "ax.set_aspect('equal')   # set the aspect ratio for the x and y axes to be equal. \n",
    "                         # This is done automatically in gdf.plot()\n",
    "    \n",
    "base = usa.plot(ax=ax, color='black')  # Set the base map, or bottom map layer\n",
    "usa1810.plot(ax=base, color='white', edgecolor=\"black\")  # draw the data with the base\n",
    "_ = ax.axis('off') # Don't show the x, y axes and labels in the plot\n",
    "ax.set_title(\"USA 2017 and 1810\")  # Give the plot a title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions?\n",
    "\n",
    "If your lost, don't worry. Many folks, myself included, scratch their head and copy matplotlib code, amazed and mystified when it works. Gradually it sinks in. You can expediate the process by reviewing any of a number of good online tutorials, like this one from [DataCamp](https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinate Reference Systems (CRS) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice anything funny about the shape of the USA as mapped above?  How does it differ from this?\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Map_of_USA_with_state_names.svg/640px-Map_of_USA_with_state_names.svg.png\" width=\"800px\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does it differ? Here's why:\n",
    "\n",
    "<img src=\"data/orange_peel_world.png\" width=\"500px\"></img>\n",
    "\n",
    "When we map data encoded with a spheriodal coordinate reference system (longitude & latitude) as though it were two dimension x,y coordinate data we get distortion!\n",
    "\n",
    "## Map Projections and CRS Transformations\n",
    "\n",
    "In order to reduce distortion in 2D maps we transform geographic coordinates to projected map coordinates.\n",
    "\n",
    "> This transformation is also necessary for may geometric calculations like area and distance that assume a 2D plane.\n",
    "\n",
    "The process for CRS transformations is:\n",
    "\n",
    "1. Make sure a `crs` is defined for the geopandas dataframe by checking the `crs` property. \n",
    "2. If it is not set, you can set it with the `crs` method.\n",
    "3. Transform it using the `to_crs` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the CRS of our gdfs\n",
    "usa.crs\n",
    "usa1810.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's an `epsg:4326`?  That's an [EPSG](http://www.epsg.org/) code for the geographic CRS known as the [World Geodectic System of 1984](https://en.wikipedia.org/wiki/World_Geodetic_System#WGS84), or `WGS84`. This is the most commonly used CRS for latitude and longitude coordinate data and is the default CRS for most mapping software when the data does not have a defined CRS.\n",
    "\n",
    "We can make our map look better by transforming it to a 2D projected `CRS`. A projected CRS applies a mathematical transformation to the data based on a [map projection](https://en.wikipedia.org/wiki/Map_projection)\n",
    "\n",
    "Common Map projections and EPSG codes for mapping USA data include:\n",
    "\n",
    "- `Web Mercator` (epsg:3857)\n",
    "- `USA Contiguious Albers` (epsg:7603)\n",
    "\n",
    "Let's try these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform geographic crs to web mercator\n",
    "usa_3857 = usa.to_crs(epsg=3857)\n",
    "usa_3857.plot(figsize=(14,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform geographic crs to USA Contiguous Albers\n",
    "usa_7603 = usa.to_crs(epsg=7603)\n",
    "usa_7603.plot(figsize=(14,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see we get very different maps of the USA depending on the CRS. Web Mercator is best suited for large geographic extents between +-60 degrees (i.e. distortion increases as you move away from equator and towards the poles). USA Contiguous Albers is best for the continental USA.  We could subset the data to remove Alaska, Hawaii and Puerto Rico.\n",
    "\n",
    "### Important Notes\n",
    "\n",
    "1. Data need to be in the same CRS in order to be mapped or analyzed together.\n",
    "2. It's not obvious what the best projected CRS is for your map or analysis. You need to review the recent literature (as these things change) and try different ones.  Here is a good starting place, [epsg.io](http://epsg.io/).\n",
    "\n",
    "\n",
    "> A detailed discussion CRS and map projections is beyond the scope of this notebook. Understanding these, however, is **necessary** for working sucessfully with geospatial data! There are a number of online resources that can be found with a web search to help you get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping Data\n",
    "\n",
    "By default maps show locations in space. Data maps, also called thematic maps, convey data values at specific locations by associating those values with map symbology like color, shape and size. \n",
    "\n",
    "In this section we will explore population data in the `Orleans Territory` from the US Census of 1810.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only interested in the `Orleans Territory` let's subset the `usa1810` data. Take another look at the geopandas dataframe to identify the column we can subset the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa1810"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `STATENAM` column includes a reference to the territory so let's use that.  Then map the result to check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orleans = usa1810[usa1810['STATENAM'] == 'Orleans Territory']\n",
    "orleans.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Orleans Territory looks alot like the state of Louisiana.\n",
    "\n",
    "### Attribute Joins\n",
    "\n",
    "In order to map data we need data associated with the locations. We have polygon data in the `orleans1810` geodataframe but no attributes of interest.\n",
    "\n",
    "In a separate file, we have 1810 population data for the Orleans Territory that was downloaded from the NHGIS. These data are in the `CSV` file `orleans_census_data1810.csv`.  We need to read the file into a `pandas` dataframe and then join the columns from that data to the `orleans` geopandas data based on a column with common data value.  This process is called an `attribute join` and is a common operation when working with geospatial data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, read in the population data from the 1810 census that we want to map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orleans_census1810 = pd.read_csv('data/orleans_census_data1810.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orleans_census1810.head()  # take a look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the `orleans_census1810` data with the `orleans` geopandas dataframe. What columns in these two data objects have common values on which the data frames can be joined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orleans.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the geopandas `merge` command to join the two dataframes.  Then take a look at the output which we call `orleans_popdata` since it contains population data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orleans_popdata = orleans.merge(orleans_census1810, on='GISJOIN')\n",
    "orleans_popdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add options to the `plot` command to map the data values to the map symbology. Consider how this is done below with the data in the `nwslave_pop` (non-white slave population) column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orleans_popdata.plot(column='nwslave_pop', cmap='Reds', edgecolor='black', legend=True, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, the parameter `cmap` stands for colormap. You can see the list of available [color maps here](https://matplotlib.org/users/colormaps.html). The full range of values in the `nwslave_pop` column is being scaled to the color palette called `Reds`.  This is called an `unclassified` or `classless` map. This map is a good first effort as it imposses no grouping on the data, thus making it easier to spot trends and outliers. But it is harder to interpret the data values within an area.\n",
    "\n",
    "A more common practice is to use a classification scheme to bin the data into classes and map those classes to a color palette. Let's try that below with `quantile` classification which is the most commonly used scheme when mapping data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orleans_popdata.plot(column='nwslave_pop', cmap='Reds', edgecolor='black', \n",
    "                     legend=True, figsize=(8,6), scheme='quantiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow that gives a very different looking map!\n",
    "\n",
    "## Challenge\n",
    "\n",
    "In the code cell below recreate the above map with the classification schemes 'equal_interval' and 'fisher_jenks' to see how the look of the map changes.\n",
    "\n",
    "> Bonus challenge: try a different colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choropleth maps\n",
    "\n",
    ">The maps we just made are called `choropleth maps`. A [choropleth maps](https://en.wikipedia.org/wiki/Choropleth_map) is a data map that colors areas, here polygons, by data values.  This are the most common type of data map. It is often also called a `heatmap`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get fancy with our choropleth maps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12,12))\n",
    "\n",
    "orleans_popdata.plot(ax=ax, column='nwslave_pop', cmap='OrRd', edgecolor='black', legend=True, scheme='fisher_jenks')\n",
    "\n",
    "for polygon, name in zip(orleans_popdata.geometry, orleans_popdata.COUNTY):\n",
    "    ax.annotate(xy=(polygon.centroid.x, polygon.centroid.y), s=name)\n",
    "\n",
    "_ = ax.axis('off')\n",
    "\n",
    "ax.set_title(\"Non-White Slave Population, Orleans Territory, 1810\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Needless to say, labels are a bit tricky, regardless of the software you use to make a map!\n",
    "\n",
    "\n",
    "## Challenge\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "1. Add a column to `orleans_popdata` called `nwslave_white` that is the ratio of non-white slaves (nwslave_pop) to the white population (white_pop)\n",
    "2. Create a choropleth map of the data values in your new column using 'fisher-jenks' classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow-up Challenge\n",
    "\n",
    "In 1791 and 1795 two slave revolts where planned, both in the same parish in Orleans Territory. Both plots were discovered and thwarted, leading to the trial and execution or emprisonment of many slaves. Soon thereafter, the German Coast Uprising of 1811 occured in a different Orleans parish. Can you use the map above to guess the two parishes in which these events occured? You can confirm your guess with a web search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping data to polygons is commonly done, but sometimes point maps are preferred. Why? Because when polygons vary greatly in size, as the US states and counties do, the size of the areas can distract from interpretting the data. Large areas pop out and small ones hide in the map.\n",
    "\n",
    "GeoPandas makes it easy to transform polygon data to point data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert Polys to Points and map\n",
    "orleans_census_points = orleans_popdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy poly to new GeoDataFrame\n",
    "orleans_popdata_pts = orleans_popdata.copy()\n",
    "\n",
    "# transform the geometry\n",
    "orleans_popdata_pts.geometry = orleans_popdata_pts['geometry'].centroid\n",
    "\n",
    "# take a look\n",
    "orleans_popdata_pts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was relatively easy! Take a look at the format of the data in the `geometry` column and note how it differs for that of `orleans_popdata`.\n",
    "\n",
    "Make a quick plot of the data to make sure it looks right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orleans_popdata_pts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get geographic context, we can plot those points on top of the polygons. Consider the code below for doing this and the resultant plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(14,14))  # Initialize the plot figure (drawing area) and axes (data area)\n",
    " \n",
    "ax.set_aspect('equal')   # set the aspect ratio for the x and y axes to be equal. \n",
    "                         # This is done automatically in gdf.plot()\n",
    "    \n",
    "base = orleans_popdata.plot(ax=ax, facecolor='white', edgecolor='grey', linewidth=0.25,)   \n",
    "orleans_popdata_pts.plot(ax=base, column='nwslave_pop', cmap='OrRd', edgecolor='black', markersize=80,\n",
    "                            legend=True, scheme='fisher_jenks')\n",
    "_ = ax.axis('off')  \n",
    "\n",
    "for polygon, name in zip(orleans_popdata.geometry, orleans_popdata.COUNTY):\n",
    "    ax.annotate(xy=(polygon.centroid.x+0.05, polygon.centroid.y), s=name, color='black')\n",
    "    \n",
    "ax.set_title(\"Non-White Slave Population, Orleans Territory, 1810\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Redo the map above with the data in the column `nwslave_white` (or the ratio of non-white slaves to whites.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "We have just touched the tip of the iceberg here in terms of mapping, manipulating and analyzing geospatial data. I hope this encourages you to check out the GeoPandas in more detail and to continue working with geospatial data in Python or in another software tool. Happy mapping!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Created by: Patty Frontiera, on 6/5/2018\n",
    "    \n",
    "Acknowledgements: This notebook borrows from that of Prof. David O'Sullivan's notebooks for [Geography-88](https://github.com/data-8/geography-88)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
