{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An introduction to computational text analysis: A more in-depth look at strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strings have some simple but powerful methods that allow us to begin working with text in more complex ways. You saw how to import a .csv as a `datascience` Table in the last notebook, but what happens when we want to import text that is not nicely organized into rows and columns? We can organize the important parts into a nice tabular structure by first identifying parts that we want. \n",
    "\n",
    "**NOTE:** We will use hand-typed and plain text (.txt) file examples in this notebook, and since the rest of the class will focus on HathiTrust Research Center resources, **know that  .html, .json, and .xml file formats are important to computational text analysis but will not be covered in this class.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1\n",
    "\n",
    "1. Store your first name in a variable named `first`.  \n",
    "2. Store your last name in a variable named `last`.  \n",
    "3. Convert `first` to all upper case letters.  \n",
    "4. Convert `last` to all lower case letters.  \n",
    "5. Combine these two string variables into a variable named `full`.  \n",
    "6. Slice out `first` from `full`.  \n",
    "7. Slice out `last` from `full`.  \n",
    "8. Slice `full` so that it contains only the last 2 characters of your first name and the first two characters of your last name.  \n",
    "9. Which string methods did you use in #3 and #4 above? How do you know they are string methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evan\n",
      "Muzzall\n",
      "EVAN\n",
      "muzzall\n",
      "Evan Muzzall\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "first = \"Evan\"\n",
    "print(first)\n",
    "last = \"Muzzall\"\n",
    "print(last)\n",
    "\n",
    "print(first.upper())\n",
    "print(last.lower())\n",
    "\n",
    "full = first + \" \" + last\n",
    "print(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muzzall\n"
     ]
    }
   ],
   "source": [
    "full[:4]\n",
    "#print(full[-7:])\n",
    "print(full[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an Mu\n"
     ]
    }
   ],
   "source": [
    "middle = full[2:7]\n",
    "print(middle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus\n",
    "What do the following commands return? Why? \n",
    "\n",
    "\"cat\" > \"category\"  \n",
    "\"cat \" * 5  \n",
    "\"cat\" + 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat2'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "\"cat\" + \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jorge Luis Borges\n",
    "\n",
    "![borges](img/borges_1921.jpg)\n",
    "\n",
    "Below is a string of [Jorge Luis Borges'](https://en.wikipedia.org/wiki/Jorge_Luis_Borges) poem \"On His Blindness\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "borges = \"\"\"In the fullness of the years, like it or not,\n",
    "a luminous mist surrounds me, unvarying, \n",
    "that breaks things down into a single thing,\n",
    "colorless, formless. Almost into a thought. \n",
    "The elemental, vast night and the day\n",
    "teeming with people have become that fog\n",
    "of constant, tentative light that does not flag,\n",
    "and lies in wait at dawn. I longed to see\n",
    "just once a human face. Unknown to me\n",
    "the closed encyclopedia, the sweet play\n",
    "in volumes I can do no more than hold, \n",
    "the tiny soaring birds, the moons of gold.\n",
    "Others have the world, for better or worse; \n",
    "I have this half-dark, and the toil of verse.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the fullness of the years, like it or not,\n",
      "a luminous mist surrounds me, unvarying, \n",
      "that breaks things down into a single thing,\n",
      "colorless, formless. Almost into a thought. \n",
      "The elemental, vast night and the day\n",
      "teeming with people have become that fog\n",
      "of constant, tentative light that does not flag,\n",
      "and lies in wait at dawn. I longed to see\n",
      "just once a human face. Unknown to me\n",
      "the closed encyclopedia, the sweet play\n",
      "in volumes I can do no more than hold, \n",
      "the tiny soaring birds, the moons of gold.\n",
      "Others have the world, for better or worse; \n",
      "I have this half-dark, and the toil of verse.\n"
     ]
    }
   ],
   "source": [
    "print(borges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make an unpreprocessed copy for use below\n",
    "borges_dirty = borges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "Tokenization is the process of splitting text into words - each word is called a \"token\" and each word has a particular \"type\". However, a word such as \"the\" might adhere to multiple tokens of \"the\" within a text.\n",
    "\n",
    "`.split` allows us to split the text based on some sort of separator. In this case, we want to split on the \"whitespace\" (the blank spaces between words). \n",
    "\n",
    "**NOTE:** remember to use your help files in the form of `help(borges.split)`\n",
    "\n",
    "Let's just look at the first six words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In', 'the', 'fullness', 'of', 'the', 'years,']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "borges.split()[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In the fullness of the years, like it or not,\\na luminous mist surrounds me, unvarying, \\nthat breaks things down into a single thing,\\ncolorless, formless',\n",
       " ' Almost into a thought',\n",
       " ' \\nThe elemental, vast night and the day\\nteeming with people have become that fog\\nof constant, tentative light that does not flag,\\nand lies in wait at dawn',\n",
       " ' I longed to see\\njust once a human face',\n",
       " ' Unknown to me\\nthe closed encyclopedia, the sweet play\\nin volumes I can do no more than hold, \\nthe tiny soaring birds, the moons of gold',\n",
       " '\\nOthers have the world, for better or worse; \\nI have this half-dark, and the toil of verse',\n",
       " '']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# challenge 2\n",
    "borges.split(\".\")#[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many characters are there in `borges`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599\n"
     ]
    }
   ],
   "source": [
    "print(len(borges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    }
   ],
   "source": [
    "print(len(borges.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many lines? (hint: a line break is represented as \\n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(borges.split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many stanzas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(borges.split(\"\\n\\n\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At which index does the word \"me\" first appear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "print(borges.find(\"me\")) # .find is \"forward search\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At which index does the word \"me\" last appear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433\n"
     ]
    }
   ],
   "source": [
    "print(borges.rfind(\"me\")) # .rfind starts at the highest index and works in reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function rfind:\n",
      "\n",
      "rfind(...) method of builtins.str instance\n",
      "    S.rfind(sub[, start[, end]]) -> int\n",
      "    \n",
      "    Return the highest index in S where substring sub is found,\n",
      "    such that sub is contained within S[start:end].  Optional\n",
      "    arguments start and end are interpreted as in slice notation.\n",
      "    \n",
      "    Return -1 on failure.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(borges.rfind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique words? (hint, use `set`!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(borges.lower().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'light', 'me', 'years,', 'closed', 'can', 'others', 'better', 'does', 'elemental,', 'in', 'thing,', 'to', 'see', 'dawn.', 'human', 'colorless,', 'day', 'flag,', 'wait', 'just', 'or', 'unvarying,', 'single', 'lies', 'with', 'gold.', 'half-dark,', 'play', 'soaring', 'no', 'fog', 'luminous', 'night', 'i', 'breaks', 'thought.', 'more', 'and', 'mist', 'have', 'sweet', 'people', 'almost', 'the', 'surrounds', 'teeming', 'constant,', 'not', 'of', 'not,', 'fullness', 'longed', 'face.', 'birds,', 'tentative', 'verse.', 'for', 'volumes', 'unknown', 'tiny', 'a', 'me,', 'that', 'like', 'down', 'vast', 'at', 'once', 'encyclopedia,', 'than', 'worse;', 'this', 'become', 'toil', 'hold,', 'into', 'do', 'formless.', 'things', 'it', 'world,', 'moons'}\n"
     ]
    }
   ],
   "source": [
    "print(set(borges.lower().split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2\n",
    "1. Using your intutition, how might you split text on commas?\n",
    "2. On periods?\n",
    "3. How do you split _all_ of `borges` on whitespace so that all words are split and printed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some fast notes about for-loops, functions, and conditionals in Python\n",
    "\n",
    "Custom functions, for-loops, and conditionals are important tools that you will want to eventually explore. Since we will use a list comprehension (looping with accumulation) to remove punctuation below, let's take a minute to talk about these important topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom functions\n",
    "\n",
    "Just like built-in functions, custom functions take some inputs and give you back desired output(s). We can define our own custom functions to use over and over again. \n",
    "\n",
    "In this case, `def` tells Python that we want to define our own function. `square` is the name of the function and it needs two arguments to work `x` and `y`. \n",
    "\n",
    "The colon symbol `:` tells Python that the code to be evaluated comes on the indented line after it.  \n",
    "\n",
    "`return` tells Python that the code after it should be printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sq_and_div(x,y):\n",
    "    return (x**2)/y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_and_div(10,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For loops\n",
    "\n",
    "For loops are useful when you want to use the same code over a range of values, data, or files. \n",
    "\n",
    "`for` tells Python that we want to write a for loop. \n",
    "\n",
    "`x` is our \"iterator\" (placeholder) variable and range is the number of times to iterate. The colon symbol `:` again tells Python that the code to be evaluated follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time is 1 o'clock\n",
      "The time is 2 o'clock\n",
      "The time is 3 o'clock\n",
      "The time is 4 o'clock\n",
      "The time is 5 o'clock\n",
      "The time is 6 o'clock\n",
      "The time is 7 o'clock\n",
      "The time is 8 o'clock\n",
      "The time is 9 o'clock\n",
      "The time is 10 o'clock\n",
      "The time is 11 o'clock\n",
      "The time is 12 o'clock\n"
     ]
    }
   ],
   "source": [
    "for x in range(1, 13):\n",
    "    print(\"The time is\", x, \"o'clock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditionals\n",
    "\n",
    "Conditionals are statements that help you assign different conditions to different pieces of data. In the case below, `if` tells Python that \"if some condition is met - do _this_\". \n",
    "\n",
    "However, \"if _some other condition_ is met - do something _else!_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What time is it (PM)?6\n",
      "The time is 6 o'clock\n"
     ]
    }
   ],
   "source": [
    "x = int(input(\"What time is it (PM)?\"))\n",
    "if x < 9:\n",
    "    print(\"The time is\", x, \"o'clock\")\n",
    "else:\n",
    "    print(\"It's getting late!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing punctuation\n",
    "\n",
    "Remember how we imported that nice string of English punctuation in the first cell of this notebook? We could manually remove all of the punctuation using the `.replace` method, but this would get old fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(type(punctuation))\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "borges_periods = borges.replace(\".\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the fullness of the years, like it or not,\n",
      "a luminous mist surrounds me, unvarying, \n",
      "that breaks things down into a single thing,\n",
      "colorless, formless  Almost into a thought  \n",
      "The elemental, vast night and the day\n",
      "teeming with people have become that fog\n",
      "of constant, tentative light that does not flag,\n",
      "and lies in wait at dawn  I longed to see\n",
      "just once a human face  Unknown to me\n",
      "the closed encyclopedia, the sweet play\n",
      "in volumes I can do no more than hold, \n",
      "the tiny soaring birds, the moons of gold \n",
      "Others have the world, for better or worse; \n",
      "I have this half-dark, and the toil of verse \n"
     ]
    }
   ],
   "source": [
    "print(borges_periods) # all periods have been successfully removed! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, what if you have tons of text and don't know exactly what punctuation is present? A quick custom function can help us remove all the punctuation from `borges`, i.e. !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for char in punctuation:\n",
    "    borges = borges.replace(char, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the fullness of the years like it or not\n",
      "a luminous mist surrounds me unvarying \n",
      "that breaks things down into a single thing\n",
      "colorless formless Almost into a thought \n",
      "The elemental vast night and the day\n",
      "teeming with people have become that fog\n",
      "of constant tentative light that does not flag\n",
      "and lies in wait at dawn I longed to see\n",
      "just once a human face Unknown to me\n",
      "the closed encyclopedia the sweet play\n",
      "in volumes I can do no more than hold \n",
      "the tiny soaring birds the moons of gold\n",
      "Others have the world for better or worse \n",
      "I have this halfdark and the toil of verse\n"
     ]
    }
   ],
   "source": [
    "print(borges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3\n",
    "\n",
    "Describe what is happening in this remove punctuation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for char in punctuation:\n",
    "    borges = borges.replace(char, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization with the `nltk` library\n",
    "\n",
    "The [`nltk` (natural language toolkit)](https://nltk.readthedocs.io/en/latest/) library can also help you tokenize your text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'the',\n",
       " 'fullness',\n",
       " 'of',\n",
       " 'the',\n",
       " 'years',\n",
       " 'like',\n",
       " 'it',\n",
       " 'or',\n",
       " 'not',\n",
       " 'a',\n",
       " 'luminous',\n",
       " 'mist',\n",
       " 'surrounds',\n",
       " 'me',\n",
       " 'unvarying',\n",
       " 'that',\n",
       " 'breaks',\n",
       " 'things',\n",
       " 'down',\n",
       " 'into',\n",
       " 'a',\n",
       " 'single',\n",
       " 'thing',\n",
       " 'colorless',\n",
       " 'formless',\n",
       " 'Almost',\n",
       " 'into',\n",
       " 'a',\n",
       " 'thought',\n",
       " 'The',\n",
       " 'elemental',\n",
       " 'vast',\n",
       " 'night',\n",
       " 'and',\n",
       " 'the',\n",
       " 'day',\n",
       " 'teeming',\n",
       " 'with',\n",
       " 'people',\n",
       " 'have',\n",
       " 'become',\n",
       " 'that',\n",
       " 'fog',\n",
       " 'of',\n",
       " 'constant',\n",
       " 'tentative',\n",
       " 'light',\n",
       " 'that',\n",
       " 'does',\n",
       " 'not',\n",
       " 'flag',\n",
       " 'and',\n",
       " 'lies',\n",
       " 'in',\n",
       " 'wait',\n",
       " 'at',\n",
       " 'dawn',\n",
       " 'I',\n",
       " 'longed',\n",
       " 'to',\n",
       " 'see',\n",
       " 'just',\n",
       " 'once',\n",
       " 'a',\n",
       " 'human',\n",
       " 'face',\n",
       " 'Unknown',\n",
       " 'to',\n",
       " 'me',\n",
       " 'the',\n",
       " 'closed',\n",
       " 'encyclopedia',\n",
       " 'the',\n",
       " 'sweet',\n",
       " 'play',\n",
       " 'in',\n",
       " 'volumes',\n",
       " 'I',\n",
       " 'can',\n",
       " 'do',\n",
       " 'no',\n",
       " 'more',\n",
       " 'than',\n",
       " 'hold',\n",
       " 'the',\n",
       " 'tiny',\n",
       " 'soaring',\n",
       " 'birds',\n",
       " 'the',\n",
       " 'moons',\n",
       " 'of',\n",
       " 'gold',\n",
       " 'Others',\n",
       " 'have',\n",
       " 'the',\n",
       " 'world',\n",
       " 'for',\n",
       " 'better',\n",
       " 'or',\n",
       " 'worse',\n",
       " 'I',\n",
       " 'have',\n",
       " 'this',\n",
       " 'halfdark',\n",
       " 'and',\n",
       " 'the',\n",
       " 'toil',\n",
       " 'of',\n",
       " 'verse']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(borges)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'the',\n",
       " 'fullness',\n",
       " 'of',\n",
       " 'the',\n",
       " 'years',\n",
       " 'like',\n",
       " 'it',\n",
       " 'or',\n",
       " 'not',\n",
       " 'a',\n",
       " 'luminous',\n",
       " 'mist',\n",
       " 'surrounds',\n",
       " 'me',\n",
       " 'unvarying',\n",
       " 'that',\n",
       " 'breaks',\n",
       " 'things',\n",
       " 'down',\n",
       " 'into',\n",
       " 'a',\n",
       " 'single',\n",
       " 'thing',\n",
       " 'colorless',\n",
       " 'formless',\n",
       " 'Almost',\n",
       " 'into',\n",
       " 'a',\n",
       " 'thought',\n",
       " 'The',\n",
       " 'elemental',\n",
       " 'vast',\n",
       " 'night',\n",
       " 'and',\n",
       " 'the',\n",
       " 'day',\n",
       " 'teeming',\n",
       " 'with',\n",
       " 'people',\n",
       " 'have',\n",
       " 'become',\n",
       " 'that',\n",
       " 'fog',\n",
       " 'of',\n",
       " 'constant',\n",
       " 'tentative',\n",
       " 'light',\n",
       " 'that',\n",
       " 'does',\n",
       " 'not',\n",
       " 'flag',\n",
       " 'and',\n",
       " 'lies',\n",
       " 'in',\n",
       " 'wait',\n",
       " 'at',\n",
       " 'dawn',\n",
       " 'I',\n",
       " 'longed',\n",
       " 'to',\n",
       " 'see',\n",
       " 'just',\n",
       " 'once',\n",
       " 'a',\n",
       " 'human',\n",
       " 'face',\n",
       " 'Unknown',\n",
       " 'to',\n",
       " 'me',\n",
       " 'the',\n",
       " 'closed',\n",
       " 'encyclopedia',\n",
       " 'the',\n",
       " 'sweet',\n",
       " 'play',\n",
       " 'in',\n",
       " 'volumes',\n",
       " 'I',\n",
       " 'can',\n",
       " 'do',\n",
       " 'no',\n",
       " 'more',\n",
       " 'than',\n",
       " 'hold',\n",
       " 'the',\n",
       " 'tiny',\n",
       " 'soaring',\n",
       " 'birds',\n",
       " 'the',\n",
       " 'moons',\n",
       " 'of',\n",
       " 'gold',\n",
       " 'Others',\n",
       " 'have',\n",
       " 'the',\n",
       " 'world',\n",
       " 'for',\n",
       " 'better',\n",
       " 'or',\n",
       " 'worse',\n",
       " 'I',\n",
       " 'have',\n",
       " 'this',\n",
       " 'halfdark',\n",
       " 'and',\n",
       " 'the',\n",
       " 'toil',\n",
       " 'of',\n",
       " 'verse']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = borges.split()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence segmentation\n",
    "\n",
    "Sentence segmentation deals with identifying sentence boundaries. We can do this by splitting on punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "borges_dirty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In the fullness of the years, like it or not,\\na luminous mist surrounds me, unvarying, \\nthat breaks things down into a single thing,\\ncolorless, formless',\n",
       " ' Almost into a thought',\n",
       " ' \\nThe elemental, vast night and the day\\nteeming with people have become that fog\\nof constant, tentative light that does not flag,\\nand lies in wait at dawn',\n",
       " ' I longed to see\\njust once a human face',\n",
       " ' Unknown to me\\nthe closed encyclopedia, the sweet play\\nin volumes I can do no more than hold, \\nthe tiny soaring birds, the moons of gold',\n",
       " '\\nOthers have the world, for better or worse; \\nI have this half-dark, and the toil of verse',\n",
       " '']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "borges_dirty.split(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `nltk` can do sentence segmentation also!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In the fullness of the years, like it or not,\\na luminous mist surrounds me, unvarying, \\nthat breaks things down into a single thing,\\ncolorless, formless.',\n",
       " 'Almost into a thought.',\n",
       " 'The elemental, vast night and the day\\nteeming with people have become that fog\\nof constant, tentative light that does not flag,\\nand lies in wait at dawn.',\n",
       " 'I longed to see\\njust once a human face.',\n",
       " 'Unknown to me\\nthe closed encyclopedia, the sweet play\\nin volumes I can do no more than hold, \\nthe tiny soaring birds, the moons of gold.',\n",
       " 'Others have the world, for better or worse; \\nI have this half-dark, and the toil of verse.']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(borges_dirty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this with the hopes of \"normalizing\" our text. There are many scenarios that make text non-normalized, but some common ones include:\n",
    "- case folding (dealing with upper and lower case letters; generally, we want to make all text lower-case).\n",
    "- removing URLs, digits, and hashtags\n",
    "- infrequent word removal\n",
    "- stop word removal\n",
    "\n",
    "Regular expressions help out greatly with these! See me during office hours if you have further questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count word frequencies\n",
    "\n",
    "We can use Python's built-in function `Counter` to count words! Let's look at the most frequent twelve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 9),\n",
       " ('of', 4),\n",
       " ('a', 4),\n",
       " ('that', 3),\n",
       " ('and', 3),\n",
       " ('have', 3),\n",
       " ('I', 3),\n",
       " ('or', 2),\n",
       " ('not', 2),\n",
       " ('me', 2)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "freq = Counter(tokens)\n",
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing stop words\n",
    "\n",
    "Yikes! The most common words in `borges` seem to be [stop words](https://en.wikipedia.org/wiki/Stop_words) such as \"the\", \"of\", and \"a\". Let's remove them because they are rarely useful in computational text analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/evan.admin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/evan.admin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/evan.admin/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words(\"english\")\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 3),\n",
       " ('In', 1),\n",
       " ('fullness', 1),\n",
       " ('years', 1),\n",
       " ('like', 1),\n",
       " ('luminous', 1),\n",
       " ('mist', 1),\n",
       " ('surrounds', 1),\n",
       " ('unvarying', 1),\n",
       " ('breaks', 1),\n",
       " ('things', 1),\n",
       " ('single', 1),\n",
       " ('thing', 1),\n",
       " ('colorless', 1),\n",
       " ('formless', 1),\n",
       " ('Almost', 1),\n",
       " ('thought', 1),\n",
       " ('The', 1),\n",
       " ('elemental', 1),\n",
       " ('vast', 1)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq2 = Counter(no_stops)\n",
    "freq2.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'fullness',\n",
       " 'years',\n",
       " 'like',\n",
       " 'luminous',\n",
       " 'mist',\n",
       " 'surrounds',\n",
       " 'unvarying',\n",
       " 'breaks',\n",
       " 'things',\n",
       " 'single',\n",
       " 'thing',\n",
       " 'colorless',\n",
       " 'formless',\n",
       " 'Almost',\n",
       " 'thought',\n",
       " 'The',\n",
       " 'elemental',\n",
       " 'vast',\n",
       " 'night',\n",
       " 'day',\n",
       " 'teeming',\n",
       " 'people',\n",
       " 'become',\n",
       " 'fog',\n",
       " 'constant',\n",
       " 'tentative',\n",
       " 'light',\n",
       " 'flag',\n",
       " 'lies',\n",
       " 'wait',\n",
       " 'dawn',\n",
       " 'I',\n",
       " 'longed',\n",
       " 'see',\n",
       " 'human',\n",
       " 'face',\n",
       " 'Unknown',\n",
       " 'closed',\n",
       " 'encyclopedia',\n",
       " 'sweet',\n",
       " 'play',\n",
       " 'volumes',\n",
       " 'I',\n",
       " 'hold',\n",
       " 'tiny',\n",
       " 'soaring',\n",
       " 'birds',\n",
       " 'moons',\n",
       " 'gold',\n",
       " 'Others',\n",
       " 'world',\n",
       " 'better',\n",
       " 'worse',\n",
       " 'I',\n",
       " 'halfdark',\n",
       " 'toil',\n",
       " 'verse']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_stops = [word for word in tokens if word not in stopwords.words('english')]\n",
    "no_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming/lemmatization\n",
    "\n",
    "Both of these terms seek to remove morphological affixes on words. \n",
    "\n",
    "If we stem the word \"eats\" we get \"eat\". If we stem the word \"sleeping\" we get \"sleep\". We stem words because we tend to focus more on the meaning of the core content of the word, rather than its tense. \n",
    "\n",
    "NLTK provides many algorithms for stemming. For English, a great baseline is the [Porter](https://github.com/nltk/nltk/blob/develop/nltk/stem/porter.py) algorithm, which is in spirit isn't that far from a bunch of regular expressions.\n",
    "\n",
    "Let's try a few! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"eats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sleep'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"sleeping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fli'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"flying\") # uh oh... flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "snowballer_stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(snowballer_stemmer.stem(\"eats\"))\n",
    "print(snowballer_stemmer.stem(\"sleeping\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(lemmatizer.lemmatize(\"leaves\")) # uh-oh..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of speech tagging\n",
    "\n",
    "Part of speech (POS) tagging assigns each token a part of speech! (i.e., noun, verg, adjective, etc.). \n",
    "\n",
    "Again, there are many different [alternatives](https://github.com/nltk/nltk/tree/develop/nltk/tag), but NLTK keeps its recommended POS tagger available through the function `pos_tag`. The tagger expects a list of tokens as input. When doing POS tagging, it is advisable **not** to remove stop words beforehand (although you are free to do it afterwards)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the fullness of the years like it or not\\na luminous mist surrounds me unvarying \\nthat breaks things down into a single thing\\ncolorless formless Almost into a thought \\nThe elemental vast night and the day\\nteeming with people have become that fog\\nof constant tentative light that does not flag\\nand lies in wait at dawn I longed to see\\njust once a human face Unknown to me\\nthe closed encyclopedia the sweet play\\nin volumes I can do no more than hold \\nthe tiny soaring birds the moons of gold\\nOthers have the world for better or worse \\nI have this halfdark and the toil of verse'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "borges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops! We forgot to remove our line breaks. Let's do so now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "borges = borges.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the fullness of the years like it or not a luminous mist surrounds me unvarying  that breaks things down into a single thing colorless formless Almost into a thought  The elemental vast night and the day teeming with people have become that fog of constant tentative light that does not flag and lies in wait at dawn I longed to see just once a human face Unknown to me the closed encyclopedia the sweet play in volumes I can do no more than hold  the tiny soaring birds the moons of gold Others have the world for better or worse  I have this halfdark and the toil of verse'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "borges # looking good! :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the fullness of the years like it or not a luminous mist surrounds me unvarying  that breaks things down into a single thing colorless formless Almost into a thought  The elemental vast night and the day teeming with people have become that fog of constant tentative light that does not flag and lies in wait at dawn I longed to see just once a human face Unknown to me the closed encyclopedia the sweet play in volumes I can do no more than hold  the tiny soaring birds the moons of gold Others have the world for better or worse  I have this halfdark and the toil of verse'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "pos_borges = borges\n",
    "pos_borges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('fullness', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('years', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('or', 'CC'),\n",
       " ('not', 'RB'),\n",
       " ('a', 'DT'),\n",
       " ('luminous', 'JJ'),\n",
       " ('mist', 'NN'),\n",
       " ('surrounds', 'NNS'),\n",
       " ('me', 'PRP'),\n",
       " ('unvarying', 'VBG'),\n",
       " ('that', 'IN'),\n",
       " ('breaks', 'JJ'),\n",
       " ('things', 'NNS'),\n",
       " ('down', 'RP'),\n",
       " ('into', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('single', 'JJ'),\n",
       " ('thing', 'NN'),\n",
       " ('colorless', 'NN'),\n",
       " ('formless', 'NN'),\n",
       " ('Almost', 'NNP'),\n",
       " ('into', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('thought', 'VBN'),\n",
       " ('The', 'DT'),\n",
       " ('elemental', 'JJ'),\n",
       " ('vast', 'JJ'),\n",
       " ('night', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('day', 'NN'),\n",
       " ('teeming', 'VBG'),\n",
       " ('with', 'IN'),\n",
       " ('people', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('become', 'VBN'),\n",
       " ('that', 'IN'),\n",
       " ('fog', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('constant', 'JJ'),\n",
       " ('tentative', 'JJ'),\n",
       " ('light', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('does', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('flag', 'VB'),\n",
       " ('and', 'CC'),\n",
       " ('lies', 'VBZ'),\n",
       " ('in', 'IN'),\n",
       " ('wait', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('dawn', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('longed', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('see', 'VB'),\n",
       " ('just', 'RB'),\n",
       " ('once', 'RB'),\n",
       " ('a', 'DT'),\n",
       " ('human', 'JJ'),\n",
       " ('face', 'NN'),\n",
       " ('Unknown', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('me', 'PRP'),\n",
       " ('the', 'DT'),\n",
       " ('closed', 'JJ'),\n",
       " ('encyclopedia', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('sweet', 'JJ'),\n",
       " ('play', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('volumes', 'NNS'),\n",
       " ('I', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('do', 'VB'),\n",
       " ('no', 'DT'),\n",
       " ('more', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('hold', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('tiny', 'JJ'),\n",
       " ('soaring', 'NN'),\n",
       " ('birds', 'NNS'),\n",
       " ('the', 'DT'),\n",
       " ('moons', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('gold', 'NN'),\n",
       " ('Others', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('better', 'JJR'),\n",
       " ('or', 'CC'),\n",
       " ('worse', 'JJR'),\n",
       " ('I', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('this', 'DT'),\n",
       " ('halfdark', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('toil', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('verse', 'NN')]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_borges = pos_tag(tokens)\n",
    "tagged_borges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What might you conclude about Borges' style of writing based on the frequencies of non-stop words and stemmed words? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why is preprocessing important?\n",
    "\n",
    "Text preprocessing is an essential first step to coding and understanding machine learning algorithms. For machine learning portions of this course, we will focus on bag of words models, namely document-term and term frequency-inverse document frequency models from the [sklearn library](http://scikit-learn.org/stable/). \n",
    "\n",
    "As previously stated, these instructions can be improved upon using regular expressions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Challenge 4\n",
    "\n",
    "We can also open data from files. Let's open up the \"poe.txt\" file from the materials you downloaded earlier. This contains the poem \"A Dream Within a Dream\" by Edgar Allen Poe. \n",
    "\n",
    "Repeat the instructions in this notebook using Poe's poem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./poe.txt\", \"r\") as myfile:\n",
    "    poe = myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take this kiss upon the brow!\n",
      "And, in parting from you now,\n",
      "Thus much let me avow —\n",
      "You are not wrong, who deem\n",
      "That my days have been a dream;\n",
      "Yet if hope has flown away\n",
      "In a night, or in a day,\n",
      "In a vision, or in none,\n",
      "Is it therefore the less gone?  \n",
      "All that we see or seem\n",
      "Is but a dream within a dream.\n",
      "\n",
      "I stand amid the roar\n",
      "Of a surf-tormented shore,\n",
      "And I hold within my hand\n",
      "Grains of the golden sand —\n",
      "How few! yet how they creep\n",
      "Through my fingers to the deep,\n",
      "While I weep — while I weep!\n",
      "O God! Can I not grasp \n",
      "Them with a tighter clasp?\n",
      "O God! can I not save\n",
      "One from the pitiless wave?\n",
      "Is all that we see or seem\n",
      "But a dream within a dream?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(poe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(poe.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
